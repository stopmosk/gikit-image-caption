{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb49a27d-6cd5-4c14-b982-6cb7ceaea73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from maskrcnn_benchmark.structures.tsv_file import TSVFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ca6a90-7250-4057-b031-d49570910323",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_root = '/mnt/Toshiba2TB/dataset_ImageCaption'\n",
    "exp_root = '../../../../datasets_proc/big_nn_nms1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8542a7-c5f3-4d61-833f-b5d98064aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_DATASET1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449055/449055 [00:00<00:00, 854793.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_DATASET2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 436727/436727 [00:00<00:00, 815164.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_DATASET3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 369671/369671 [00:00<00:00, 832508.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_DATASET4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 385483/385483 [00:00<00:00, 729705.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9988/9988 [00:00<00:00, 307582.29it/s]\n"
     ]
    }
   ],
   "source": [
    "img_paths = dict()\n",
    "\n",
    "folder_list = [f for f in os.listdir(orig_root) if '.' not in f]\n",
    "\n",
    "for folder in folder_list[:5]:\n",
    "    print(folder, flush=True)\n",
    "    img_list = [f for f in os.listdir(op.join(orig_root, folder))]\n",
    "    for img_filename in tqdm(img_list):\n",
    "        img_paths[img_filename] = op.join(orig_root, folder, img_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69abab18-3c0b-4438-9197-5d4c14f58126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Toshiba2TB/dataset_ImageCaption/CC_DATASET1/0000006ee283bee151d361963b2907c1.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\n",
    "img_paths[list(img_paths.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd8129f-db2d-477a-b6fa-ccd8999759ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2620065"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(op.join(orig_root, 'Final_EN.json')) as f:\n",
    "    dataset_captions = json.load(f)\n",
    "\n",
    "dataset_captions = dataset_captions['annotations']\n",
    "len(dataset_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f945fc-b28e-40a8-803e-62ea6ee9da7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1762097"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_keys = set(c['file_name'] for c in dataset_captions)\n",
    "len(img_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e6143f-eab6-43ea-8d98-a2fab01484eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2620065/2620065 [00:00<00:00, 2765091.24it/s]\n"
     ]
    }
   ],
   "source": [
    "captions_by_num = dict()\n",
    "\n",
    "for caption in tqdm(dataset_captions):\n",
    "    cap = caption['file_name']\n",
    "    if cap not in captions_by_num:\n",
    "        captions_by_num[cap] = 1\n",
    "    else:\n",
    "        captions_by_num[cap] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0424870-2de7-4fdb-8fd0-46e7a6266e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1536397), (2, 7550), (3, 7552), (4, 32013), (5, 174719), (6, 329), (7, 45), (8, 118), (9, 266), (10, 579), (11, 648), (12, 948), (13, 827), (14, 11), (15, 24), (16, 36), (17, 2), (19, 2), (20, 4), (21, 2), (25, 1), (26, 3), (29, 1), (31, 1), (35, 2), (36, 1), (39, 1), (64, 1), (99, 1), (104, 1), (105, 3), (109, 1), (111, 1), (117, 1), (118, 1), (120, 1), (128, 1), (165, 1), (167, 1), (384, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1762062"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate counts of captions per image over dataset\n",
    "\n",
    "counts = dict()\n",
    "\n",
    "for count in captions_by_num.values():\n",
    "    if count not in counts:\n",
    "        counts[count] = 1\n",
    "    else:\n",
    "        counts[count] += 1\n",
    "\n",
    "print(sorted(counts.items(), key=lambda x:x[0]))\n",
    "\n",
    "# remove images with more than 16 captions\n",
    "\n",
    "img_keys_filtered = [name for (name, count) in captions_by_num.items() if count <= 16]\n",
    "len(img_keys_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86bb4b9f-e579-4a6a-b091-55df30eef540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter keys\n",
    "\n",
    "json_keys = set(img_keys_filtered)\n",
    "file_keys = set(img_paths.keys())\n",
    "\n",
    "img_keys_filtered = json_keys.intersection(file_keys)\n",
    "img_keys_filtered = list(img_keys_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2408edbb-5f3f-40f5-82bc-8adece5bc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15406\n"
     ]
    }
   ],
   "source": [
    "# Split dataset to train/val/test\n",
    "\n",
    "random.shuffle(img_keys_filtered)\n",
    "split_cnt = len(img_keys_filtered) // 100\n",
    "print(split_cnt)\n",
    "\n",
    "splits = {\n",
    "    'train': img_keys_filtered[split_cnt * 2:],\n",
    "    'val':img_keys_filtered[split_cnt: split_cnt * 2],\n",
    "    'test': img_keys_filtered[: split_cnt],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acaf182a-5fb0-4249-8d65-b6a9f850c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink image if big\n",
    "\n",
    "def scale_img(img):\n",
    "    height, width = img.shape[:2]\n",
    "    max_height = 1000\n",
    "    max_width = 1000\n",
    "\n",
    "    # only shrink if img is bigger than required\n",
    "    if max_height < height or max_width < width:\n",
    "        # get scaling factor\n",
    "        scaling_factor = max_height / float(height)\n",
    "        if max_width/float(width) < scaling_factor:\n",
    "            scaling_factor = max_width / float(width)\n",
    "        # resize image\n",
    "        img = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ceec61a-8963-49f5-a74d-6fc619017fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_writer(values, tsv_file):\n",
    "    #mkdir(op.dirname(tsv_file))\n",
    "    lineidx_file = op.splitext(tsv_file)[0] + '.lineidx'\n",
    "    idx = 0\n",
    "    tsv_file_tmp = tsv_file + '.tmp'\n",
    "    lineidx_file_tmp = lineidx_file + '.tmp'\n",
    "    with open(tsv_file_tmp, 'w') as fp, open(lineidx_file_tmp, 'w') as fpidx:\n",
    "        assert values is not None\n",
    "        for value in values:\n",
    "            assert value is not None\n",
    "            value = [v if type(v)!=bytes else v.decode('utf-8') for v in value]\n",
    "            v = '{0}\\n'.format('\\t'.join(map(str, value)))\n",
    "            fp.write(v)\n",
    "            fpidx.write(str(idx) + '\\n')\n",
    "            idx = idx + len(v)\n",
    "    os.rename(tsv_file_tmp, tsv_file)\n",
    "    os.rename(lineidx_file_tmp, lineidx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "018a9bbb-9abc-4641-a5eb-89a755dd937b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'val', 'test'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439a2a5-beb7-4250-b87e-8dd7a78e7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    exp_encoded_img_file = op.join(exp_root, f'{split}.img.tsv')\n",
    "    exp_hw_file = op.join(exp_root, f'{split}.hw.tsv')\n",
    "    \n",
    "    lineidx_file = op.splitext(exp_encoded_img_file)[0] + '.lineidx'\n",
    "    idx = 0\n",
    "    \n",
    "    tsv_file_tmp = exp_encoded_img_file + '.tmp'\n",
    "    lineidx_file_tmp = lineidx_file + '.tmp'\n",
    "\n",
    "    rows_hw = []\n",
    "    \n",
    "    with open(tsv_file_tmp, 'w') as fp, open(lineidx_file_tmp, 'w') as fpidx:\n",
    "        for img_p in tqdm(splits[split]):  # [:20000]):\n",
    "            img_key = img_p.split('.')[0]\n",
    "            img_path = img_paths[img_p]\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            img = scale_img(img)\n",
    "            height = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "\n",
    "            img_encoded_str = base64.b64encode(cv2.imencode('.jpg', img)[1])\n",
    "            row = [img_key, img_encoded_str]\n",
    "            value = [v if type(v)!=bytes else v.decode('utf-8') for v in row]\n",
    "            v = '\\t'.join(map(str, value)) + '\\n'\n",
    "            fp.write(v)\n",
    "            fpidx.write(str(idx) + '\\n')\n",
    "            idx = idx + len(v)\n",
    "            \n",
    "            row_hw = [img_key, json.dumps([{'height': height, 'width': width}])]\n",
    "            rows_hw.append(row_hw)\n",
    "    \n",
    "    os.rename(tsv_file_tmp, exp_encoded_img_file)\n",
    "    os.rename(lineidx_file_tmp, lineidx_file)\n",
    "\n",
    "    tsv_writer(rows_hw, exp_hw_file)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11729b82-f88f-48b4-9b2c-836acc241722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in splits:\n",
    "#     exp_hw_file = op.join(exp_root, f'{split}.hw.tsv')\n",
    "    \n",
    "#     rows_hw = []\n",
    "#     for img_p in tqdm(splits[split]):\n",
    "#         img_key = img_p.split('.')[0]\n",
    "#         img_path = img_paths[img_p]\n",
    "\n",
    "#         img = cv2.imread(img_path)\n",
    "#         if img is None:\n",
    "#             continue\n",
    "#         img = scale_img(img)\n",
    "#         height = img.shape[0]\n",
    "#         width = img.shape[1]\n",
    "#         row_hw = [img_key, json.dumps([{'height': height, 'width': width}])]\n",
    "#         rows_hw.append(row_hw)\n",
    "    \n",
    "#     tsv_writer(rows_hw, exp_hw_file)\n",
    "\n",
    "# print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb2e2051-c449-40eb-9772-12517f9ce50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'a1650e00b6261e99a6bbe6fe13919302.jpg',\n",
       " 'caption': 'author : a life in photography -- in pictures',\n",
       " 'category_id': -1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = splits['val'][0]\n",
    "dataset_captions[0]\n",
    "#k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc90258-b78b-4c0f-880f-abf92d1ac355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1509745/1509745 [00:10<00:00, 150876.44it/s]\n",
      "100%|██████████| 15406/15406 [00:00<00:00, 102118.22it/s]\n",
      "100%|██████████| 15406/15406 [00:00<00:00, 103780.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1509745"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run cell only if we need to re-read keys from generated TSVs\n",
    "exp_root = '/mnt/Toshiba2TB/cc_vvl_nms1'\n",
    "\n",
    "img_splits = dict()\n",
    "\n",
    "for split in splits:\n",
    "    tsv = TSVFile(op.join(exp_root, f'{split}.label.tsv'))\n",
    "    keys = [tsv.seek(i)[0] for i in tqdm(range(tsv.num_rows()))]\n",
    "    img_splits[split] = keys\n",
    "\n",
    "len(img_splits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d28c824-efa5-4da5-bcf0-f7748f91ae91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 'a1650e00b6261e99a6bbe6fe13919302',\n",
       " 'id': 1,\n",
       " 'caption': 'author : a life in photography -- in pictures'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dict with img_key : {img_key, id, caption}\n",
    "\n",
    "ds_caps_by_key = {\n",
    "    s['file_name'][:-4]: {\n",
    "        'image_id': s['file_name'][:-4],\n",
    "        'id': i + 1,\n",
    "        'caption': s['caption'],\n",
    "    } for (i, s) in enumerate(dataset_captions)\n",
    "}\n",
    "\n",
    "ds_caps_by_key['a1650e00b6261e99a6bbe6fe13919302']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bccff0c-f33c-4b60-9880-777a8fe0b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_root = '/mnt/Toshiba2TB/cc_vvl_nms1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ccd6536-e005-4cfb-bbba-4ffce21af882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:20<00:00,  6.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'image_id': '8d71c508fc505357f78ebd7653edc54f',\n",
       "  'id': 788901,\n",
       "  'caption': 'an aerial view of the campus'},\n",
       " {'image_id': 'bd4d9437fef6643a77f06fb47c3db104',\n",
       "  'id': 841564,\n",
       "  'caption': \"there 's only one     grime artist made sure the crowd knew she was back for good , with her name emblazoned across the stage\"},\n",
       " {'image_id': 'cca63ad121aa5ee9ce1f83d0b7e3df8d',\n",
       "  'id': 630792,\n",
       "  'caption': 'false teeth biting a bullet in a cocktail glass'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter captions for splits\n",
    "\n",
    "for split in tqdm(splits):\n",
    "    \n",
    "    # Get current split samples from dataset\n",
    "    \n",
    "    if img_splits is not None:  # ???????\n",
    "        out_captions = [ds_caps_by_key[img_key] for img_key in img_splits[split]]\n",
    "    else:\n",
    "        out_captions = [ds_caps_by_key[img_key[:-4]] for img_key in splits[split]]              \n",
    "    \n",
    "    # Generate captions in COCO format\n",
    "\n",
    "    idim = []\n",
    "    for cap in out_captions:\n",
    "        idim.append({'id': cap['image_id'], 'file_name': cap['image_id']})\n",
    "\n",
    "    out_captions_coco_fmt = {'annotations': out_captions, 'images': idim, 'type': 'captions', 'info': 'dummy', 'licenses': 'dummy'}\n",
    "\n",
    "    # Save JSON\n",
    "\n",
    "    with open(os.path.join(exp_root, f'{split}_caption.json'), 'w') as fp:\n",
    "        json.dump(out_captions, fp)\n",
    "\n",
    "    with open(os.path.join(exp_root, f'{split}_caption_coco_format.json'), 'w') as f:\n",
    "        json.dump(out_captions_coco_fmt, f)\n",
    "\n",
    "out_captions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c566da-db59-441f-a9bb-45bef1ad09e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
