{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb49a27d-6cd5-4c14-b982-6cb7ceaea73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "#from maskrcnn_benchmark.structures.tsv_file_ops import tsv_reader, tsv_writer\n",
    "#from maskrcnn_benchmark.structures.tsv_file_ops import generate_linelist_file\n",
    "#from maskrcnn_benchmark.structures.tsv_file_ops import generate_hw_file\n",
    "#from maskrcnn_benchmark.structures.tsv_file import TSVFile\n",
    "#from maskrcnn_benchmark.data.datasets.utils.image_ops import img_from_base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ca6a90-7250-4057-b031-d49570910323",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_root = '/mnt/Toshiba2TB/dataset_ImageCaption'\n",
    "exp_root = '/mnt/Toshiba2TB/dataset_hic_encoded_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8542a7-c5f3-4d61-833f-b5d98064aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449055/449055 [00:00<00:00, 836196.47it/s]\n",
      "100%|██████████| 436727/436727 [00:00<00:00, 842034.38it/s]\n",
      "100%|██████████| 369671/369671 [00:00<00:00, 778060.41it/s]\n",
      "100%|██████████| 385483/385483 [00:00<00:00, 761970.89it/s]\n",
      "100%|██████████| 9988/9988 [00:00<00:00, 513983.12it/s]\n",
      "100%|██████████| 31784/31784 [00:00<00:00, 642163.02it/s]\n",
      "100%|██████████| 25347/25347 [00:00<00:00, 575420.81it/s]\n",
      "100%|██████████| 82773/82773 [00:00<00:00, 815792.36it/s]\n",
      "100%|██████████| 23954/23954 [00:00<00:00, 560441.56it/s]\n",
      "100%|██████████| 3322/3322 [00:00<00:00, 101121.84it/s]\n",
      "100%|██████████| 40500/40500 [00:00<00:00, 699646.66it/s]\n",
      "100%|██████████| 7750/7750 [00:00<00:00, 595628.98it/s]\n"
     ]
    }
   ],
   "source": [
    "img_paths = dict()\n",
    "\n",
    "folder_list = [f for f in os.listdir(orig_root) if '.' not in f]\n",
    "\n",
    "for folder in folder_list:\n",
    "    img_list = [f for f in os.listdir(op.join(orig_root, folder))]\n",
    "    for img_filename in tqdm(img_list):\n",
    "        img_paths[img_filename] = op.join(orig_root, folder, img_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69abab18-3c0b-4438-9197-5d4c14f58126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Toshiba2TB/dataset_ImageCaption/CC_DATASET1/0000006ee283bee151d361963b2907c1.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\n",
    "img_paths[list(img_paths.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd8129f-db2d-477a-b6fa-ccd8999759ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2620065"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(op.join(orig_root, 'Final_EN.json')) as f:\n",
    "    dataset_captions = json.load(f)\n",
    "\n",
    "dataset_captions = dataset_captions['annotations']\n",
    "len(dataset_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f945fc-b28e-40a8-803e-62ea6ee9da7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1762097"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_keys = set(c['file_name'] for c in dataset_captions)\n",
    "len(img_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e6143f-eab6-43ea-8d98-a2fab01484eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2620065/2620065 [00:00<00:00, 2655829.99it/s]\n"
     ]
    }
   ],
   "source": [
    "captions_by_num = dict()\n",
    "\n",
    "for caption in tqdm(dataset_captions):\n",
    "    cap = caption['file_name']\n",
    "    if cap not in captions_by_num:\n",
    "        captions_by_num[cap] = 1\n",
    "    else:\n",
    "        captions_by_num[cap] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0424870-2de7-4fdb-8fd0-46e7a6266e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1536397), (2, 7550), (3, 7552), (4, 32013), (5, 174719), (6, 329), (7, 45), (8, 118), (9, 266), (10, 579), (11, 648), (12, 948), (13, 827), (14, 11), (15, 24), (16, 36), (17, 2), (19, 2), (20, 4), (21, 2), (25, 1), (26, 3), (29, 1), (31, 1), (35, 2), (36, 1), (39, 1), (64, 1), (99, 1), (104, 1), (105, 3), (109, 1), (111, 1), (117, 1), (118, 1), (120, 1), (128, 1), (165, 1), (167, 1), (384, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1762062"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate counts of captions per image over dataset\n",
    "\n",
    "counts = dict()\n",
    "\n",
    "for count in captions_by_num.values():\n",
    "    if count not in counts:\n",
    "        counts[count] = 1\n",
    "    else:\n",
    "        counts[count] += 1\n",
    "\n",
    "print(sorted(counts.items(), key=lambda x:x[0]))\n",
    "\n",
    "# remove images with more than 16 captions\n",
    "\n",
    "img_keys_filtered = [name for (name, count) in captions_by_num.items() if count <= 16]\n",
    "len(img_keys_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86bb4b9f-e579-4a6a-b091-55df30eef540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter keys\n",
    "\n",
    "json_keys = set(img_keys_filtered)\n",
    "file_keys = set(img_paths.keys())\n",
    "\n",
    "img_keys_filtered = json_keys.intersection(file_keys)\n",
    "img_keys_filtered = list(img_keys_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2408edbb-5f3f-40f5-82bc-8adece5bc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to train/val/test\n",
    "\n",
    "random.shuffle(img_keys_filtered)\n",
    "split_10 = len(img_keys_filtered) // 10\n",
    "\n",
    "splits = {\n",
    "    'train': img_keys_filtered[split_10 * 2:],\n",
    "    'val':img_keys_filtered[split_10: split_10 * 2],\n",
    "    'test': img_keys_filtered[: split_10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acaf182a-5fb0-4249-8d65-b6a9f850c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink image if big\n",
    "\n",
    "def scale_img(img):\n",
    "    height, width = img.shape[:2]\n",
    "    max_height = 1000\n",
    "    max_width = 1000\n",
    "\n",
    "    # only shrink if img is bigger than required\n",
    "    if max_height < height or max_width < width:\n",
    "        # get scaling factor\n",
    "        scaling_factor = max_height / float(height)\n",
    "        if max_width/float(width) < scaling_factor:\n",
    "            scaling_factor = max_width / float(width)\n",
    "        # resize image\n",
    "        img = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ceec61a-8963-49f5-a74d-6fc619017fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_writer(values, tsv_file):\n",
    "    #mkdir(op.dirname(tsv_file))\n",
    "    lineidx_file = op.splitext(tsv_file)[0] + '.lineidx'\n",
    "    idx = 0\n",
    "    tsv_file_tmp = tsv_file + '.tmp'\n",
    "    lineidx_file_tmp = lineidx_file + '.tmp'\n",
    "    with open(tsv_file_tmp, 'w') as fp, open(lineidx_file_tmp, 'w') as fpidx:\n",
    "        assert values is not None\n",
    "        for value in values:\n",
    "            assert value is not None\n",
    "            value = [v if type(v)!=bytes else v.decode('utf-8') for v in value]\n",
    "            v = '{0}\\n'.format('\\t'.join(map(str, value)))\n",
    "            fp.write(v)\n",
    "            fpidx.write(str(idx) + '\\n')\n",
    "            idx = idx + len(v)\n",
    "    os.rename(tsv_file_tmp, tsv_file)\n",
    "    os.rename(lineidx_file_tmp, lineidx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7abbe050-3dd5-47c3-a2bd-4c4a0b07af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in splits:\n",
    "#     rows = []\n",
    "#     rows_hw = []\n",
    "\n",
    "#     exp_encoded_img_file = op.join(exp_root, f'{split}.img.tsv')\n",
    "#     exp_hw_file = op.join(exp_root, f'{split}.hw.tsv')\n",
    "\n",
    "#     for img_p in tqdm(splits[split][:5]):\n",
    "#         img_key = img_p.split('.')[0]\n",
    "#         img_path = img_paths[img_p]\n",
    "\n",
    "#         img = cv2.imread(img_path)\n",
    "#         if img is None:\n",
    "#             continue\n",
    "\n",
    "#         img = scale_img(img)\n",
    "#         # im_pil = Image.fromarray(img)\n",
    "#         # im_pil.show()\n",
    "#         height = img.shape[0]\n",
    "#         width = img.shape[1]\n",
    "\n",
    "#         img_encoded_str = base64.b64encode(cv2.imencode('.jpg', img)[1])\n",
    "#         row = [img_key, img_encoded_str]\n",
    "#         # print(row[1][800:900] , flush=True)\n",
    "#         rows.append(row)\n",
    "\n",
    "#         row_hw = [img_key, json.dumps([{'height': height, 'width': width}])]\n",
    "#         rows_hw.append(row_hw)\n",
    "    \n",
    "#     tsv_writer(rows, exp_encoded_img_file)\n",
    "#     tsv_writer(rows_hw, exp_hw_file)\n",
    "\n",
    "# print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0439a2a5-beb7-4250-b87e-8dd7a78e7d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [10:20<00:00, 32.21it/s]\n",
      "100%|██████████| 20000/20000 [10:26<00:00, 31.92it/s]\n",
      "100%|██████████| 20000/20000 [10:33<00:00, 31.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    exp_encoded_img_file = op.join(exp_root, f'{split}.img.tsv')\n",
    "    exp_hw_file = op.join(exp_root, f'{split}.hw.tsv')\n",
    "    \n",
    "    lineidx_file = op.splitext(exp_encoded_img_file)[0] + '.lineidx'\n",
    "    idx = 0\n",
    "    \n",
    "    tsv_file_tmp = exp_encoded_img_file + '.tmp'\n",
    "    lineidx_file_tmp = lineidx_file + '.tmp'\n",
    "\n",
    "    rows_hw = []\n",
    "    \n",
    "    with open(tsv_file_tmp, 'w') as fp, open(lineidx_file_tmp, 'w') as fpidx:\n",
    "        for img_p in tqdm(splits[split][:20000]):\n",
    "            img_key = img_p.split('.')[0]\n",
    "            img_path = img_paths[img_p]\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            img = scale_img(img)\n",
    "            height = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "\n",
    "            img_encoded_str = base64.b64encode(cv2.imencode('.jpg', img)[1])\n",
    "            row = [img_key, img_encoded_str]\n",
    "            value = [v if type(v)!=bytes else v.decode('utf-8') for v in row]\n",
    "            v = '\\t'.join(map(str, value)) + '\\n'\n",
    "            fp.write(v)\n",
    "            fpidx.write(str(idx) + '\\n')\n",
    "            idx = idx + len(v)\n",
    "            \n",
    "            row_hw = [img_key, json.dumps([{'height': height, 'width': width}])]\n",
    "            rows_hw.append(row_hw)\n",
    "    \n",
    "    os.rename(tsv_file_tmp, exp_encoded_img_file)\n",
    "    os.rename(lineidx_file_tmp, lineidx_file)\n",
    "\n",
    "    tsv_writer(rows_hw, exp_hw_file)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e2051-c449-40eb-9772-12517f9ce50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
