{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49a27d-6cd5-4c14-b982-6cb7ceaea73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from maskrcnn_benchmark.structures.tsv_file import TSVFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca6a90-7250-4057-b031-d49570910323",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_root = '/mnt/Toshiba2TB/dataset_ImageCaption'\n",
    "exp_root = '../../../../datasets_proc/big_nn_nms1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8542a7-c5f3-4d61-833f-b5d98064aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = dict()\n",
    "\n",
    "folder_list = [f for f in os.listdir(orig_root) if '.' not in f]\n",
    "\n",
    "for folder in folder_list[:5]:\n",
    "    print(folder, flush=True)\n",
    "    img_list = [f for f in os.listdir(op.join(orig_root, folder))]\n",
    "    for img_filename in tqdm(img_list):\n",
    "        img_paths[img_filename] = op.join(orig_root, folder, img_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abab18-3c0b-4438-9197-5d4c14f58126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "img_paths[list(img_paths.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd8129f-db2d-477a-b6fa-ccd8999759ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(op.join(orig_root, 'Final_EN.json')) as f:\n",
    "    dataset_captions = json.load(f)\n",
    "\n",
    "dataset_captions = dataset_captions['annotations']\n",
    "len(dataset_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f945fc-b28e-40a8-803e-62ea6ee9da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_keys = set(c['file_name'] for c in dataset_captions)\n",
    "len(img_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6143f-eab6-43ea-8d98-a2fab01484eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_by_num = dict()\n",
    "\n",
    "for caption in tqdm(dataset_captions):\n",
    "    cap = caption['file_name']\n",
    "    if cap not in captions_by_num:\n",
    "        captions_by_num[cap] = 1\n",
    "    else:\n",
    "        captions_by_num[cap] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0424870-2de7-4fdb-8fd0-46e7a6266e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate counts of captions per image over dataset\n",
    "\n",
    "counts = dict()\n",
    "\n",
    "for count in captions_by_num.values():\n",
    "    if count not in counts:\n",
    "        counts[count] = 1\n",
    "    else:\n",
    "        counts[count] += 1\n",
    "\n",
    "print(sorted(counts.items(), key=lambda x:x[0]))\n",
    "\n",
    "# remove images with more than 16 captions\n",
    "\n",
    "img_keys_filtered = [name for (name, count) in captions_by_num.items() if count <= 16]\n",
    "len(img_keys_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb4b9f-e579-4a6a-b091-55df30eef540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter keys\n",
    "\n",
    "json_keys = set(img_keys_filtered)\n",
    "file_keys = set(img_paths.keys())\n",
    "\n",
    "img_keys_filtered = json_keys.intersection(file_keys)\n",
    "img_keys_filtered = list(img_keys_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408edbb-5f3f-40f5-82bc-8adece5bc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to train/val/test\n",
    "\n",
    "random.shuffle(img_keys_filtered)\n",
    "split_cnt = len(img_keys_filtered) // 100\n",
    "print(split_cnt)\n",
    "\n",
    "splits = {\n",
    "    'train': img_keys_filtered[split_cnt * 2:],\n",
    "    'val':img_keys_filtered[split_cnt: split_cnt * 2],\n",
    "    'test': img_keys_filtered[: split_cnt],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf182a-5fb0-4249-8d65-b6a9f850c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink image if big\n",
    "\n",
    "def scale_img(img):\n",
    "    height, width = img.shape[:2]\n",
    "    max_height = 1000\n",
    "    max_width = 1000\n",
    "\n",
    "    # only shrink if img is bigger than required\n",
    "    if max_height < height or max_width < width:\n",
    "        # get scaling factor\n",
    "        scaling_factor = max_height / float(height)\n",
    "        if max_width/float(width) < scaling_factor:\n",
    "            scaling_factor = max_width / float(width)\n",
    "        # resize image\n",
    "        img = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceec61a-8963-49f5-a74d-6fc619017fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_writer(values, tsv_file):\n",
    "    #mkdir(op.dirname(tsv_file))\n",
    "    lineidx_file = op.splitext(tsv_file)[0] + '.lineidx'\n",
    "    idx = 0\n",
    "    tsv_file_tmp = tsv_file + '.tmp'\n",
    "    lineidx_file_tmp = lineidx_file + '.tmp'\n",
    "    with open(tsv_file_tmp, 'w') as fp, open(lineidx_file_tmp, 'w') as fpidx:\n",
    "        assert values is not None\n",
    "        for value in values:\n",
    "            assert value is not None\n",
    "            value = [v if type(v)!=bytes else v.decode('utf-8') for v in value]\n",
    "            v = '{0}\\n'.format('\\t'.join(map(str, value)))\n",
    "            fp.write(v)\n",
    "            fpidx.write(str(idx) + '\\n')\n",
    "            idx = idx + len(v)\n",
    "    os.rename(tsv_file_tmp, tsv_file)\n",
    "    os.rename(lineidx_file_tmp, lineidx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a9bbb-9abc-4641-a5eb-89a755dd937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439a2a5-beb7-4250-b87e-8dd7a78e7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    exp_encoded_img_file = op.join(exp_root, f'{split}.img.tsv')\n",
    "    exp_hw_file = op.join(exp_root, f'{split}.hw.tsv')\n",
    "    \n",
    "    lineidx_file = op.splitext(exp_encoded_img_file)[0] + '.lineidx'\n",
    "    idx = 0\n",
    "    \n",
    "    tsv_file_tmp = exp_encoded_img_file + '.tmp'\n",
    "    lineidx_file_tmp = lineidx_file + '.tmp'\n",
    "\n",
    "    rows_hw = []\n",
    "    \n",
    "    with open(tsv_file_tmp, 'w') as fp, open(lineidx_file_tmp, 'w') as fpidx:\n",
    "        for img_p in tqdm(splits[split]):  # [:20000]):\n",
    "            img_key = img_p.split('.')[0]\n",
    "            img_path = img_paths[img_p]\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            img = scale_img(img)\n",
    "            height = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "\n",
    "            img_encoded_str = base64.b64encode(cv2.imencode('.jpg', img)[1])\n",
    "            row = [img_key, img_encoded_str]\n",
    "            value = [v if type(v)!=bytes else v.decode('utf-8') for v in row]\n",
    "            v = '\\t'.join(map(str, value)) + '\\n'\n",
    "            fp.write(v)\n",
    "            fpidx.write(str(idx) + '\\n')\n",
    "            idx = idx + len(v)\n",
    "            \n",
    "            row_hw = [img_key, json.dumps([{'height': height, 'width': width}])]\n",
    "            rows_hw.append(row_hw)\n",
    "    \n",
    "    os.rename(tsv_file_tmp, exp_encoded_img_file)\n",
    "    os.rename(lineidx_file_tmp, lineidx_file)\n",
    "\n",
    "    tsv_writer(rows_hw, exp_hw_file)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11729b82-f88f-48b4-9b2c-836acc241722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in splits:\n",
    "#     exp_hw_file = op.join(exp_root, f'{split}.hw.tsv')\n",
    "    \n",
    "#     rows_hw = []\n",
    "#     for img_p in tqdm(splits[split]):\n",
    "#         img_key = img_p.split('.')[0]\n",
    "#         img_path = img_paths[img_p]\n",
    "\n",
    "#         img = cv2.imread(img_path)\n",
    "#         if img is None:\n",
    "#             continue\n",
    "#         img = scale_img(img)\n",
    "#         height = img.shape[0]\n",
    "#         width = img.shape[1]\n",
    "#         row_hw = [img_key, json.dumps([{'height': height, 'width': width}])]\n",
    "#         rows_hw.append(row_hw)\n",
    "    \n",
    "#     tsv_writer(rows_hw, exp_hw_file)\n",
    "\n",
    "# print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e2051-c449-40eb-9772-12517f9ce50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = splits['val'][0]\n",
    "dataset_captions[0]\n",
    "#k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc90258-b78b-4c0f-880f-abf92d1ac355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell only if we need to re-read keys from generated TSVs\n",
    "\n",
    "# img_splits = dict()\n",
    "\n",
    "# for split in splits:\n",
    "#     tsv = TSVFile(f'/mnt/Toshiba2TB/big_vinvl_oscar/{split}.label.tsv')\n",
    "#     keys = [tsv.seek(i)[0] for i in tqdm(range(tsv.num_rows()))]\n",
    "#     img_splits[split] = keys\n",
    "\n",
    "# len(img_splits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28c824-efa5-4da5-bcf0-f7748f91ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict with img_key : {img_key, id, caption}\n",
    "\n",
    "ds_caps_by_key = {\n",
    "    s['file_name'][:-4]: {\n",
    "        'image_id': s['file_name'][:-4],\n",
    "        'id': i + 1,\n",
    "        'caption': s['caption'],\n",
    "    } for (i, s) in enumerate(dataset_captions)\n",
    "}\n",
    "\n",
    "ds_caps_by_key['a1650e00b6261e99a6bbe6fe13919302']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd6536-e005-4cfb-bbba-4ffce21af882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter captions for splits\n",
    "\n",
    "for split in tqdm(splits):\n",
    "    \n",
    "    # Get current split samples from dataset\n",
    "    \n",
    "    if img_splits is not None:  # ???????\n",
    "        out_captions = [ds_caps_by_key[img_key] for img_key in img_splits[split]]\n",
    "    else:\n",
    "        out_captions = [ds_caps_by_key[img_key[:-4]] for img_key in splits[split]]              \n",
    "    \n",
    "    # Generate captions in COCO format\n",
    "\n",
    "    idim = []\n",
    "    for cap in out_captions:\n",
    "        idim.append({'id': cap['image_id'], 'file_name': cap['image_id']})\n",
    "\n",
    "    out_captions_coco_fmt = {'annotations': out_captions, 'images': idim, 'type': 'captions', 'info': 'dummy', 'licenses': 'dummy'}\n",
    "\n",
    "    # Save JSON\n",
    "\n",
    "    with open(os.path.join(exp_root, f'{split}_caption.json'), 'w') as fp:\n",
    "        json.dump(out_captions, fp)\n",
    "\n",
    "    with open(os.path.join(exp_root, f'{split}_caption_coco_format.json'), 'w') as f:\n",
    "        json.dump(out_captions_coco_fmt, f)\n",
    "\n",
    "out_captions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c566da-db59-441f-a9bb-45bef1ad09e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
