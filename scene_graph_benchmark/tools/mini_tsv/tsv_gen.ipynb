{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb49a27d-6cd5-4c14-b982-6cb7ceaea73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import tsv_reader, tsv_writer\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import generate_linelist_file\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import generate_hw_file\n",
    "from maskrcnn_benchmark.structures.tsv_file import TSVFile\n",
    "from maskrcnn_benchmark.data.datasets.utils.image_ops import img_from_base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72ca6a90-7250-4057-b031-d49570910323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig_root = '../../../datasets/textcaps_orig'\n",
    "orig_root = '../../../../datasets/textcaps_orig'\n",
    "\n",
    "# orig_img_train_val_dir = op.join(orig_root, 'train_val_images')  # Contains train & val images\n",
    "# orig_img_test_dir = op.join(orig_root, 'test_images')\n",
    "\n",
    "orig_cap_filenames = {split: f'TextCaps_0.1_{split}.json' for split in ['train', 'val', 'test']}\n",
    "\n",
    "# exp_root = '../../../datasets/textcaps_nn'\n",
    "exp_root = '../../../../datasets/textcaps_nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a7a93e5-e883-4683-9585-8ce6e3471ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TextCaps captions\n",
    "\n",
    "caps = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "for split in caps.keys():\n",
    "    cap_filename = op.join(orig_root, orig_cap_filenames[split])\n",
    "    with open(cap_filename) as fp:\n",
    "        captions_json = json.load(fp)\n",
    "    caps[split] = captions_json['data']\n",
    "\n",
    "# caps['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec1b7d70-575b-49ab-adb0-8232e99d24d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21953\n",
      "3166\n",
      "3289\n"
     ]
    }
   ],
   "source": [
    "img_list = {split_name: set([item['image_id'] + '.jpg' for item in caps[split_name]]) for split_name in caps.keys()}\n",
    "for split in img_list:\n",
    "    print(len(img_list[split]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4affb0d-4e07-47e8-a0ba-1581afc448ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TextCaps EasyOCR OCR tags\n",
    "\n",
    "with open(op.join(orig_root, 'ocr_tags.json')) as fp:\n",
    "    ocr_json = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f2d48756-8b58-4efc-8040-e38670f03986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = 'val'\n",
    "# images_wh = {el['image_id']: [el['image_width'], el['image_height']] for el in caps[split]}\n",
    "# images_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7bcdc74f-92aa-4c2f-b64c-65bc8bef6e09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21953/21953 [00:00<00:00, 191600.32it/s]\n",
      "100%|██████████| 3166/3166 [00:00<00:00, 217559.29it/s]\n"
     ]
    }
   ],
   "source": [
    "split_img_ids = {\n",
    "    'train': set([item['image_id'] for item in caps['train']]),\n",
    "    'val': set([item['image_id'] for item in caps['val']]),\n",
    "}\n",
    "\n",
    "# GENERATE JSON \n",
    "for split in ['train', 'val']:\n",
    "    images_wh = {el['image_id']: [el['image_width'], el['image_height']] for el in caps[split]}\n",
    "    ocr_filename = op.join(exp_root, f'{split}_ocr_easyocr.json')\n",
    "    ocr_split = [el for el in ocr_json if el['image_id'] in split_img_ids[split]]\n",
    "    for item in tqdm(ocr_split):\n",
    "        for block in item['data']:\n",
    "            b = block[0]\n",
    "            # print(b)\n",
    "            w, h = images_wh[item['image_id']]\n",
    "            # print(w, h)\n",
    "            x1, y1, x2, y2 = b[0]/w, b[1]/h, b[2]/w, b[3]/h\n",
    "            assert x1 <= 1.0 \n",
    "            assert y1 <= 1.0\n",
    "            #assert x2 <= 1.0\n",
    "            #if y2 > 1:\n",
    "            #    print(b, h)\n",
    "            #    print(y2)\n",
    "            #assert y2 <= 1.0\n",
    "            block[0] = [x1, y1, x2, y2]\n",
    "        # print(item)\n",
    "    # a = ocr_split[1]\n",
    "    # w, h = images_wh[a['image_id']]\n",
    "    # print(a)\n",
    "    # print(w, h)\n",
    "    with open(ocr_filename, 'w') as fp:\n",
    "        json.dump(ocr_split, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21d893ea-1265-4dab-8edb-8c261ffebd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TextCaps Rosetta OCR tags\n",
    "\n",
    "ocr_rosetta_json = {}\n",
    "for split in ['train', 'val']:\n",
    "    with open(op.join(orig_root, f'TextVQA_Rosetta_OCR_v0.2_{split}.json')) as fp:\n",
    "        ocr_rosetta_json[split] = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e53a4b4b-e35b-4e99-b023-bad7333797de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "011e7e629fb9ae7b \n",
      " LESS \n",
      " LESS \n",
      " {'width': 0.053537655621767044, 'height': 0.03051217645406723, 'rotation': 0, 'roll': 0, 'pitch': 0, 'yaw': 0, 'top_left_x': 0.0947766974568367, 'top_left_y': 0.3009840250015259} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_img = ocr_rosetta_json['train']['data'][0]\n",
    "print(\n",
    "    sample_img['image_id'], '\\n',\n",
    "    sample_img['ocr_tokens'][0], '\\n',\n",
    "    sample_img['ocr_info'][0]['word'], '\\n',\n",
    "    sample_img['ocr_info'][0]['bounding_box'], '\\n',\n",
    "    # sample_img['ocr_tokens'][1], '\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db2b4148-92ae-4473-b534-3dbfed882e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_rosetta_splits = {}\n",
    "for split in ['train', 'val']:\n",
    "    split_list = []\n",
    "    for img in ocr_rosetta_json[split]['data']:\n",
    "        split_list.append({\n",
    "            'image_id': img['image_id'],\n",
    "            'data': [[\n",
    "                [0, 0, 0, 0, block['bounding_box']['width'], block['bounding_box']['height']], \n",
    "                block['word'], \n",
    "                1.0] for block in img['ocr_info']]\n",
    "        })\n",
    "    ocr_rosetta_splits[split] = split_list\n",
    "# ocr_rosetta_splits['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "89ba2b0a-1372-42af-8c79-995080916285",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_img_ids = {\n",
    "    'train': set([item['image_id'] for item in caps['train']]),\n",
    "    'val': set([item['image_id'] for item in caps['val']]),\n",
    "}\n",
    "\n",
    "# GENERATE JSON \n",
    "for split in ['train', 'val']:\n",
    "    ocr_filename = op.join(exp_root, f'{split}_ocr_rosetta.json')\n",
    "    ocr_split = [el for el in ocr_rosetta_splits[split] if el['image_id'] in split_img_ids[split]]\n",
    "    with open(ocr_filename, 'w') as fp:\n",
    "        json.dump(ocr_split, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7abbe050-3dd5-47c3-a2bd-4c4a0b07af55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21953/21953 [06:04<00:00, 60.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../datasets/textcaps_nn/train.img.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3166/3166 [00:53<00:00, 59.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../datasets/textcaps_nn/val.img.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3289/3289 [00:55<00:00, 58.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../datasets/textcaps_nn/test.img.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in caps.keys():\n",
    "    rows = []\n",
    "    rows_label = []\n",
    "    rows_hw = []\n",
    "\n",
    "    # i = 2\n",
    "    for img_p in tqdm(img_list[split]):\n",
    "        img_key = img_p.split('.')[0]\n",
    "        img_path = op.join(orig_root, f\"{'test' if split=='test' else 'train_val_images/train'}_images\", img_p)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_encoded_str = base64.b64encode(cv2.imencode('.jpg', img)[1])\n",
    "        row = [img_key, img_encoded_str]\n",
    "        # print(row[1][800:900] , flush=True)\n",
    "        rows.append(row)\n",
    "\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        row_hw = [img_key, json.dumps([{'height': height, 'width': width}])]\n",
    "        rows_hw.append(row_hw)\n",
    "        # i -= 1\n",
    "        # if i == 0:\n",
    "        #     break\n",
    "        \n",
    "    exp_encoded_img_file = op.join(exp_root, f'{split}.img.tsv')\n",
    "    exp_hw_file = op.join(exp_root, f'{split}.hw.tsv')\n",
    "    print(exp_encoded_img_file, flush=True)\n",
    "    tsv_writer(rows, exp_encoded_img_file)\n",
    "    # tsv_writer(rows_label, label_file)\n",
    "    tsv_writer(rows_hw, exp_hw_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a88477fc-697c-4438-8471-b0646cb39743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caps['val'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b4892d6f-79ec-4bbc-b35b-545354ad72f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 'caef3d1e97c2cf15', 'image_classes': ['Person', 'Box', 'Table', 'Clothing', 'Book'], 'flickr_original_url': 'https://farm6.staticflickr.com/8620/16450641419_1348e01994_o.jpg', 'flickr_300k_url': 'https://c5.staticflickr.com/9/8620/16450641419_daf4ae8ee4_z.jpg', 'image_width': 1024, 'image_height': 1024, 'set_name': 'val', 'image_name': 'caef3d1e97c2cf15', 'image_path': 'train/caef3d1e97c2cf15.jpg', 'caption_id': 200000000, 'caption_str': 'A book about CEOs is sitting on top of a box.', 'caption_tokens': ['<s>', 'a', 'book', 'about', 'ceos', 'is', 'sitting', 'on', 'top', 'of', 'a', 'box', '</s>'], 'reference_strs': ['A book about CEOs is sitting on top of a box.', 'a book called CEO (Customer Engagement Officer) by Mark Hillary.', 'A book titled CEO (Customer Engagement Officer) on top of a cardboard box.', 'A book by Mark Hillary titled CEO sits on top of a box', \"a book labeled 'CEO(cusotmer engagement officer) by mark hillary\"], 'reference_tokens': [['<s>', 'a', 'book', 'about', 'ceos', 'is', 'sitting', 'on', 'top', 'of', 'a', 'box', '</s>'], ['<s>', 'a', 'book', 'called', 'ceo', '(', 'customer', 'engagement', 'officer', ')', 'by', 'mark', 'hillary', '</s>'], ['<s>', 'a', 'book', 'titled', 'ceo', '(', 'customer', 'engagement', 'officer', ')', 'on', 'top', 'of', 'a', 'cardboard', 'box', '</s>'], ['<s>', 'a', 'book', 'by', 'mark', 'hillary', 'titled', 'ceo', 'sits', 'on', 'top', 'of', 'a', 'box', '</s>'], ['<s>', 'a', 'book', 'labeled', \"'\", 'ceo', '(', 'cusotmer', 'engagement', 'officer', ')', 'by', 'mark', 'hillary', '</s>']]}\n"
     ]
    }
   ],
   "source": [
    "def generate_cap_json(split: str):\n",
    "    captions = []\n",
    "    cap_idx = 0\n",
    "    for sample in caps[split]:\n",
    "        image_id = sample['image_id']\n",
    "        caption_str = sample['caption_str']\n",
    "        captions.append(\n",
    "            {\n",
    "                'image_id': image_id,\n",
    "                'id': cap_idx,\n",
    "                'caption': caption_str,\n",
    "            }\n",
    "        )\n",
    "        cap_idx +=1\n",
    "        print(sample)\n",
    "        break\n",
    "    captions = sorted(captions, key=lambda k: k['image_id'])\n",
    "#     print(captions[:10])\n",
    "    return captions\n",
    "\n",
    "generate_cap_json('val');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "300794f7-c1c6-474a-8ed8-2186d267d64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image_id': '0000599864fd15b3', 'id': 10210, 'caption': 'Turqouise bus with the numbers \"29267222\" right behind a group of people taking a picture.'}, {'image_id': '0000599864fd15b3', 'id': 68612, 'caption': 'Five people pose for a photo as the number 5 bus passes in the background.'}, {'image_id': '0000599864fd15b3', 'id': 68743, 'caption': 'Five people pose in front of a bus that advertises for a Hong Kong company with the phone number 2926 7222.'}, {'image_id': '0000599864fd15b3', 'id': 104407, 'caption': 'A group of people are posing for a picture in front of a bus with the number 5 on it.'}, {'image_id': '0000599864fd15b3', 'id': 109362, 'caption': 'Double decker bus number 5 is a bright teal color.'}, {'image_id': '0000e8b36676338b', 'id': 176, 'caption': 'Oddly shaped bus that is apparently for private use only.'}, {'image_id': '0000e8b36676338b', 'id': 70087, 'caption': 'black and white bus with felix private above windshield and license plate of dbu 889'}, {'image_id': '0000e8b36676338b', 'id': 71638, 'caption': 'A very old bus has felix and private written in its destination windows'}, {'image_id': '0000e8b36676338b', 'id': 71876, 'caption': 'a vehicle with the letters DBU on the front'}, {'image_id': '0000e8b36676338b', 'id': 73228, 'caption': 'A classic vehicle that looks like it is a cross between a bus and a van has the words Felix Private over the windshield.'}]\n",
      "[{'image_id': '0004c9478eeda995', 'id': 2251, 'caption': \"A place named Stella's serves cocktails to its customers.\"}, {'image_id': '0004c9478eeda995', 'id': 12601, 'caption': 'An entrance has a sign with the business name Stella Caffe on it.'}, {'image_id': '0004c9478eeda995', 'id': 12726, 'caption': 'A storefront has the name Stella on a sign outside.'}, {'image_id': '0004c9478eeda995', 'id': 13124, 'caption': 'Stella Cafe is on the corner of a street.'}, {'image_id': '0004c9478eeda995', 'id': 13153, 'caption': 'a caffe called stella next to a fine paper store'}, {'image_id': '00054dab88635bdb', 'id': 185, 'caption': 'A car show with people looking at cars at Becker Auto Body'}, {'image_id': '00054dab88635bdb', 'id': 1083, 'caption': 'Car that is driving pass people and becker auto body'}, {'image_id': '00054dab88635bdb', 'id': 9937, 'caption': 'A red muscle car with the license plate IDH 1969 drives past Becker Auto Body.'}, {'image_id': '00054dab88635bdb', 'id': 10000, 'caption': 'Red car that has the letters SS on the front.'}, {'image_id': '00054dab88635bdb', 'id': 10688, 'caption': 'Red car with a plate that says TDH1969 on it.'}]\n"
     ]
    }
   ],
   "source": [
    "# GENERATE JSON \n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    cap_filename = op.join(exp_root, f'{split}_caption.json')\n",
    "    with open(cap_filename, 'w') as fp:\n",
    "        json.dump(generate_cap_json(split), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c2850ec-7d17-4236-ab7f-09f91866a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO FORMAT JSON \n",
    "\n",
    "for split in ['val']:  #, 'test']:\n",
    "    cap_filename = op.join(exp_root, f'{split}_caption_coco_format.json')\n",
    "    json_annotations = generate_cap_json(split)\n",
    "    json_images = [{'id': ann['image_id'], 'image_name': ann['image_id']} for ann in json_annotations]\n",
    "    json_all = {\n",
    "        'annotations': json_annotations,\n",
    "        'images': json_images,\n",
    "        'type': 'captions',\n",
    "        'info': 'dummy',\n",
    "        'licenses': 'dummy',\n",
    "    }\n",
    "    \n",
    "    with open(cap_filename, 'w') as fp:\n",
    "        json.dump(json_all, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efde60e-bec0-4013-a5f9-443191c4fab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
