{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb49a27d-6cd5-4c14-b982-6cb7ceaea73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import tsv_reader, tsv_writer\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import generate_linelist_file\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import generate_hw_file\n",
    "from maskrcnn_benchmark.structures.tsv_file import TSVFile\n",
    "from maskrcnn_benchmark.data.datasets.utils.image_ops import img_from_base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ca6a90-7250-4057-b031-d49570910323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig_root = '../../../datasets/textcaps_orig'\n",
    "orig_root = '../../../../datasets/textcaps_orig'\n",
    "\n",
    "# orig_img_train_val_dir = op.join(orig_root, 'train_val_images')  # Contains train & val images\n",
    "# orig_img_test_dir = op.join(orig_root, 'test_images')\n",
    "\n",
    "orig_cap_filenames = {split: f'TextCaps_0.1_{split}.json' for split in ['train', 'val', 'test']}\n",
    "\n",
    "# exp_root = '../../../datasets/textcaps_nn'\n",
    "exp_root = '../../../../datasets/textcaps_nn'\n",
    "\n",
    "# cap_exp = '_caption.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a7a93e5-e883-4683-9585-8ce6e3471ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "for split in caps.keys():\n",
    "    cap_filename = op.join(orig_root, orig_cap_filenames[split])\n",
    "    with open(cap_filename) as fp:\n",
    "        captions_json = json.load(fp)\n",
    "    caps[split] = captions_json['data']\n",
    "\n",
    "# caps['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1b7d70-575b-49ab-adb0-8232e99d24d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21953\n",
      "3166\n",
      "3289\n"
     ]
    }
   ],
   "source": [
    "img_list = {split_name: set([item['image_id'] + '.jpg' for item in caps[split_name]]) for split_name in caps.keys()}\n",
    "for split in img_list:\n",
    "    print(len(img_list[split]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7abbe050-3dd5-47c3-a2bd-4c4a0b07af55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21953/21953 [06:04<00:00, 60.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../datasets/textcaps_nn/train.img.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3166/3166 [00:53<00:00, 59.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../datasets/textcaps_nn/val.img.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3289/3289 [00:55<00:00, 58.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../datasets/textcaps_nn/test.img.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in caps.keys():\n",
    "    rows = []\n",
    "    rows_label = []\n",
    "    rows_hw = []\n",
    "\n",
    "    # i = 2\n",
    "    for img_p in tqdm(img_list[split]):\n",
    "        img_key = img_p.split('.')[0]\n",
    "        img_path = op.join(orig_root, f\"{'test' if split=='test' else 'train_val_images/train'}_images\", img_p)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_encoded_str = base64.b64encode(cv2.imencode('.jpg', img)[1])\n",
    "        row = [img_key, img_encoded_str]\n",
    "        # print(row[1][800:900] , flush=True)\n",
    "        rows.append(row)\n",
    "\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        row_hw = [img_key, json.dumps([{'height': height, 'width': width}])]\n",
    "        rows_hw.append(row_hw)\n",
    "        # i -= 1\n",
    "        # if i == 0:\n",
    "        #     break\n",
    "        \n",
    "    exp_encoded_img_file = op.join(exp_root, f'{split}.img.tsv')\n",
    "    exp_hw_file = op.join(exp_root, f'{split}.hw.tsv')\n",
    "    print(exp_encoded_img_file, flush=True)\n",
    "    tsv_writer(rows, exp_encoded_img_file)\n",
    "    # tsv_writer(rows_label, label_file)\n",
    "    tsv_writer(rows_hw, exp_hw_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a88477fc-697c-4438-8471-b0646cb39743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caps['val'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4892d6f-79ec-4bbc-b35b-545354ad72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cap_json(split: str):\n",
    "    captions = []\n",
    "    cap_idx = 0\n",
    "    for sample in caps[split]:\n",
    "        image_id = sample['image_id']\n",
    "        caption_str = sample['caption_str']\n",
    "        captions.append(\n",
    "            {\n",
    "                'image_id': image_id,\n",
    "                'id': cap_idx,\n",
    "                'caption': caption_str,\n",
    "            }\n",
    "        )\n",
    "        cap_idx +=1\n",
    "    captions = sorted(captions, key=lambda k: k['image_id'])\n",
    "#     print(captions[:10])\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "300794f7-c1c6-474a-8ed8-2186d267d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'val']:\n",
    "    cap_filename = op.join(exp_root, f'{split}_caption.json')\n",
    "    with open(cap_filename, 'w') as fp:\n",
    "        json.dump(generate_cap_json(split), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c2850ec-7d17-4236-ab7f-09f91866a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['val']:  #, 'test']:\n",
    "    cap_filename = op.join(exp_root, f'{split}_caption_coco_format.json')\n",
    "    json_annotations = generate_cap_json(split)\n",
    "    json_images = [{'id': ann['image_id'], 'image_name': ann['image_id']} for ann in json_annotations]\n",
    "    json_all = {\n",
    "        'annotations': json_annotations,\n",
    "        'images': json_images,\n",
    "        'type': 'captions',\n",
    "        'info': 'dummy',\n",
    "        'licenses': 'dummy',\n",
    "    }\n",
    "    \n",
    "    with open(cap_filename, 'w') as fp:\n",
    "        json.dump(json_all, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efde60e-bec0-4013-a5f9-443191c4fab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
